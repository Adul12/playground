{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: Code is mostly re-used from https://github.com/moduIo/Deep-Q-network/blob/master/DQN.ipynb\n",
    "# Code may change with more clean-ups and explanation\n",
    "import gym\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dqn_agent import DQN_Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import blend_images, process_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Breakout-v4', render_mode=\"rgb_array\")\n",
    "state_size = (105, 80, 1)\n",
    "action_size = env.action_space.n\n",
    "agent = DQN_Agent(state_size, action_size)\n",
    "\n",
    "episodes = 50\n",
    "batch_size = 64\n",
    "skip_start = 90  # Breakout-v0 waits for 90 actions before the episode begins\n",
    "total_time = 0   # Counter for total number of steps taken\n",
    "all_rewards = 0  # Used to compute avg reward over time\n",
    "blend = 4        # Number of images to blend\n",
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend = 4\n",
    "max_steps_per_episode = 2000\n",
    "for e in range(episodes):\n",
    "    total_reward = 0\n",
    "    game_score = 0\n",
    "    state_reset = env.reset()\n",
    "    # print(state_reset)\n",
    "    state = process_frame(state_reset[0])\n",
    "    images = deque(maxlen=blend)  # Array of images to be blended\n",
    "    images.append(state)\n",
    "    \n",
    "    for skip in range(skip_start): # skip the start of each game\n",
    "        env.step(0)\n",
    "    \n",
    "    # generate an episode\n",
    "    for time in range(max_steps_per_episode):\n",
    "        total_time += 1\n",
    "        \n",
    "        # Every update_rate timesteps we update the target network parameters\n",
    "        if total_time % agent.update_rate == 0:\n",
    "            # TODO: Update the target model by copying weights from Qnetwork\n",
    "            agent.update_target_model()\n",
    "        \n",
    "        # Return the avg of the last 4 frames\n",
    "        state = blend_images(images, state_size, blend)\n",
    "        \n",
    "        # TODO: Choose and apply action\n",
    "        action = 0\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        \n",
    "        # TODO: Process the frame and save it to memory\n",
    "        \n",
    "        # Update state, and rewards\n",
    "        state = next_state\n",
    "        game_score += reward\n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            all_rewards += game_score\n",
    "            \n",
    "            print(\"episode: {}/{}, game score: {}, reward: {}, avg reward: {}, time: {}, total time: {}\"\n",
    "                  .format(e+1, episodes, game_score, total_reward, all_rewards/(e+1), time, total_time))   \n",
    "            break\n",
    "\n",
    "    if len(agent.memory) > batch_size:\n",
    "        # TODO train\n",
    "        pass\n",
    "\n",
    "    # TODO: Save model every n (try 10 or 25) episodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# agent.save('models/5k-memory_100-games')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "!pip install IPython\n",
    "!pip install matplotlib\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render())\n",
    "    plt.title(\"Step: %d %s\" % (step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "game_score = 0\n",
    "done = False\n",
    "reward = 0\n",
    "env.reset()\n",
    "for t in range(2000):\n",
    "    for skip in range(skip_start): # skip the start of each game\n",
    "        env.step(0)\n",
    "    show_state(env, t)\n",
    "    total_time += 1\n",
    "    \n",
    "    # Return the avg of the last 4 frames\n",
    "    state = blend_images(images, state_size, blend)\n",
    "    \n",
    "    # Transition Dynamics\n",
    "    action = agent.greedy_act(state)\n",
    "    next_state, reward, done, _, _ = env.step(action)\n",
    "    \n",
    "    # Return the avg of the last 4 frames\n",
    "    next_state = process_frame(next_state)\n",
    "    images.append(next_state)\n",
    "    next_state = blend_images(images, state_size, blend)\n",
    "        \n",
    "    state = next_state\n",
    "    game_score += reward\n",
    "    reward -= 1  # Punish behavior which does not accumulate reward\n",
    "    total_reward += reward\n",
    "    time.sleep(0.05)\n",
    "    if done:\n",
    "        all_rewards += game_score\n",
    "        \n",
    "        print(\"game score: {}, reward: {}\"\n",
    "                .format(game_score, total_reward))\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
